<!DOCTYPE HTML>
<html lang="en">

<head>
  <title>Aditya Parameshwaran | PhD Candidate | Formal Verification & Robotics</title>
  <meta name="author" content="Aditya Parameshwaran">
  <meta name="description"
    content="Aditya Parameshwaran - PhD Candidate at Clemson University specializing in neurosymbolic deep learning, formal verification, and controls for robotics.">
  <meta name="keywords"
    content="Aditya Parameshwaran, Mechanical Engineering, PhD, Clemson University, robotics, neural networks, formal verification, ICCPS, SEVIN, Autonomous Vehicles">

  <!-- Google Scholar Metadata for "Scalable and Interpretable Verification..." -->
  <meta name="citation_title"
    content="Scalable and Interpretable Verification of Image-based Neural Network Controllers for Autonomous Vehicles">
  <meta name="citation_author" content="Parameshwaran, Aditya">
  <meta name="citation_author" content="Wang, Yue">
  <meta name="citation_publication_date" content="2025">
  <meta name="citation_conference_title" content="ACM/IEEE International Conference on Cyber-Physical Systems (ICCPS)">
  <meta name="citation_pdf_url" content="https://aparame.github.io/aditya_website/data/SEVIN_ICCPS_2025.pdf">
  <meta name="robots" content="index, follow">
  <meta name="google-site-verification" content="oz0uV9dnE8OwGglc-pfasCrLc1LvhjbWlVbHEeVWEgw" />
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <!-- Fonts -->
  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link href="https://fonts.googleapis.com/css2?family=Inter:wght@100..900&display=swap" rel="stylesheet">

  <!-- Bootstrap CSS -->
  <link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.3/dist/css/bootstrap.min.css" rel="stylesheet">
  <!-- Bootstrap Icons -->
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap-icons@1.11.3/font/bootstrap-icons.min.css">
  <!-- Your custom stylesheet -->
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
</head>

<body>
  <div class="page-wrapper">
    <!-- Sidebar Navigation -->
    <nav class="sidebar">
      <div class="sidebar-header">
        <h2>Aditya P.</h2>
      </div>

      <div class="sidebar-nav">
        <a class="nav-link" href="#home"><i class="bi bi-house-door"></i> Home</a>
        <a class="nav-link" href="#education"><i class="bi bi-book"></i> Education</a>
        <a class="nav-link" href="#experience"><i class="bi bi-briefcase"></i> Experience</a>
        <a class="nav-link" href="#projects"><i class="bi bi-code-square"></i> Projects</a>
        <a class="nav-link" href="#research"><i class="bi bi-journal-text"></i> Research</a>
        <a class="nav-link" href="./data/AdityaResume.pdf" target="_blank"><i class="bi bi-file-earmark-person"></i>
          CV</a>
      </div>

      <div class="footer">
        <p>&copy; 2025 Aditya Parameshwaran</p>
      </div>
    </nav>

    <!-- Main Content -->
    <main class="main-content">
      <div class="container pt-5 pb-5">
        <!-- Profile Section -->
        <section class="content-container">
          <div class="row align-items-center">
            <div class="col-lg-8">
              <h1 class="mb-4">Aditya Parameshwaran</h1>
              <div class="mb-4">
                <p>
                  I am a PhD. candidate in the <a href="https://www.clemson.edu/cecas/departments/me/index.html"
                    target="_blank">Mechanical Engineering</a> department at Clemson University. I work at the <a
                    href="https://yue6.people.clemson.edu/index.php" target="_blank">Interdisciplinary Intelligent
                    Research Laboratory</a> at Clemson University under <a
                    href="https://www.clemson.edu/cecas/departments/me/people/faculty/wang.html" target="_blank">Dr.
                    Yue
                    "Sophie" Wang</a>. I have also worked with a larger consortium of researchers at <a
                    href="https://www.clemson.edu/cecas/vipr-gs/index.html" target="_blank">VIPR-GS</a> group with the
                  Automotive Department at <a href="https://cuicar.com/" target="_blank">CU-ICAR</a>. Before this, I
                  completed my M.S. from Mechanical Engineering at Purdue University and my B.E. in
                  Mechanical Engineering at University of Pune.
                </p>
              </div>
              <div class="contact-links text-center mb-4">
                <a href="mailto:adiparamesh@gmail.com" target="_blank"><i class="bi bi-envelope-fill fs-4"></i></a>
                <a href="./data/AdityaResume.pdf" target="_blank">CV</a>
                <a href="https://scholar.google.com/citations?user=Oz75U7wAAAAJ&hl=en&oi=ao" target="_blank">Scholar</a>
                <a href="https://github.com/aparame" target="_blank"><i class="bi bi-github fs-4"></i></a>
                <a href="https://www.linkedin.com/in/adi2810/" target="_blank"><i class="bi bi-linkedin fs-4"></i></a>
              </div>
            </div>
            <div class="col-lg-4">
              <img alt="profile photo" src="./images/AdityaProfile.png" class="profile-image">
            </div>
          </div>
        </section>

        <!-- Education Section -->
        <section id="education">
          <div class="section-header">
            <h3 class="section-title">Education</h3>
          </div>
          <div class="education-list">
            <div class="edu-item">
              <img src="./images/clemson.jpg" alt="Clemson Logo" class="logo-img">
              <div class="edu-main">
                <h4>PhD, Mechanical Engineering</h4>
                <span class="edu-inst">Clemson University</span>
              </div>
              <span class="edu-year">2022 - Present</span>
            </div>
            <div class="edu-item">
              <img src="./images/purdue.png" alt="Purdue Logo" class="logo-img">
              <div class="edu-main">
                <h4>MS, Mechanical Engineering</h4>
                <span class="edu-inst">Purdue University</span>
              </div>
              <span class="edu-year">2019 - 2021</span>
            </div>
            <div class="edu-item">
              <!-- Spacer for alignment -->
              <div class="logo-img" style="width:60px"></div>
              <div class="edu-main">
                <h4>BE, Mechanical Engineering</h4>
                <span class="edu-inst">MIT Pune</span>
              </div>
              <span class="edu-year">2015 - 2018</span>
            </div>
          </div>
        </section>

        <!-- Experience Section -->
        <section id="experience">
          <div class="section-header">
            <h3 class="section-title">Experience</h3>
          </div>
          <div class="timeline">

            <!-- VIPR-GS -->
            <div class="timeline-item">
              <div class="timeline-dot"></div>
              <div class="timeline-content">
                <div class="timeline-header">
                  <div>
                    <h4 class="role-title">Research Assistant (VIPR-GS)</h4>
                    <span class="company-name">Clemson University</span>
                  </div>
                  <!-- Approximated dates based on project description "side projects for US Army VIPR Centre" and resume timeline -->
                  <span class="edu-year">2022 - 2023</span>
                </div>
                <p>
                  Worked with a consortium of researchers at the <strong>VIPR-GS</strong> group. Focused on integrating
                  <strong>Semantic 3D Mapping</strong> tools for off-road ground robot applications.
                </p>
                <ul>
                  <li>Deployed <strong>Semantic 3D Mapping</strong> on Husky robots using Octomap library.</li>
                  <li>Fused semantically segmented RGB data with LiDAR point clouds for environment understanding.</li>
                </ul>
              </div>
            </div>

            <!-- Wabtec -->
            <div class="timeline-item">
              <div class="timeline-dot"></div>
              <div class="timeline-content">
                <div class="timeline-header">
                  <div>
                    <h4 class="role-title">Robotics Researcher</h4>
                    <span class="company-name">WABTEC Corporation</span>
                  </div>
                  <!-- Approximated dates based on "collaboration since completing MS at Purdue" -->
                  <span class="edu-year">2019 - 2021</span>
                </div>
                <p>
                  Contributed to the development of an <strong>Autonomous Train Robot</strong> for track health
                  monitoring.
                </p>
                <ul>
                  <li>Developed autonomous navigation for railway tracks using LiDAR, stereo cameras, and IMU.</li>
                  <li>Implemented <strong>Semantic 3D Mapping</strong> to create high-fidelity maps of track
                    environments.
                  </li>
                  <li>Deployed CNN models on NVIDIA Jetson AGX for real-time traffic sign recognition.</li>
                </ul>
              </div>
            </div>

          </div>
        </section>

        <!-- Research Section -->
        <section class="content-container" id="research">
          <div class="section-header">
            <h3 class="section-title">Research</h3>
          </div>

          <p style="text-align: justify;" class="mb-4">
            My research interests lie in neurosymbolic deep learning, formal verification and controls for robotics
            and
            autonomous vehicle applications.
            I have worked on developing path planning and navigation tools for ground robots using formal tools like
            temporal languages <a href="https://github.com/aparame/Temporal_Logic_Guided_Robot_Navigation">[1]</a> <a
              href="https://github.com/aparame/Faster_TLG-RN">[2]</a>.
            I have also worked on integrating 3D semantic mapping tools for off-road ground robot applications using
            the
            <a href="https://octomap.github.io/" target="_blank">octomap</a> library.
            Currently, I am developing neurosymbolic tools to formally verify convolutional neural networks and neural
            network controllers for complex dynamical systems.
          </p>

          <div class="research-items">
            <!-- Research Item 1 -->

            <!-- Research Item 2 -->
            <div class="card research-card">
              <div class="row g-0">
                <div class="col-md-4">
                  <div class="dual-media-container">
                    <div class="media-item">
                      <img src="images/research/images/ICCPS_approach.png" alt="ICCPS approach" class="research-image">
                    </div>
                    <div class="media-item">
                      <img src="images/research/images/ICCPS_reconstruction.png" alt="ICCPS images"
                        class="research-image">
                    </div>
                  </div>
                </div>
                <div class="col-md-8">
                  <div class="card-body">
                    <h5 class="card-title">
                      <a href="https://scholar.google.com/citations?view_op=view_citation&hl=en&user=Oz75U7wAAAAJ&citation_for_view=Oz75U7wAAAAJ:qjMakFHDy7sC"
                        target="_blank" class="text-decoration-none">
                        <span class="papertitle">Scalable and Interpretable Verification of Image-based Neural Network
                          Controllers for Autonomous Vehicles </span>
                      </a>
                    </h5>
                    <p class="card-text">
                      <i>ICCPS, 2025</i>
                    </p>
                    <div class="mb-2">
                      <span class="tech-tag">PyTorch</span>
                      <span class="tech-tag">Generative AI</span>
                      <span class="tech-tag">ML</span>
                      <span class="tech-tag">CARLA</span>
                    </div>
                    <p class="card-text">
                      <a href="https://aparame.github.io/aditya_website/" class="text-decoration-none"><b>Aditya
                          Parameshwaran</b></a>,
                      <a href="https://yue6.people.clemson.edu/index.php" class="text-decoration-none">Yue Wang</a>
                    </p>

                    <p class="card-text">
                      SEVIN (Scalable and Explainable Verification of Image-Based Neural Network Controllers) uses
                      Variational Autoencoders to encode high-dimensional images
                      into an explainable latent space, creating annotated convex polytopes that enable efficient
                      formal verification of neural network controllers for autonomous vehicles.
                      This approach reduces computational complexity, enhances scalability,
                      improves robustness against real-world perturbations, and provides explainable insights into
                      controller behavior for safety-critical systems. This work will be presented
                      at ICCPS 2025, part of the CPS-IoT week at Irvine, California.
                    </p>
                    <div class="mt-3">
                      <a href="https://dl.acm.org/doi/abs/10.1145/3716550.3722037" target="_blank"
                        class="btn btn-sm btn-outline-primary me-2">Paper</a>
                      <a href="https://github.com/aparame/SEVIN_ICCPS_RE_Package" target="_blank"
                        class="btn btn-sm btn-outline-primary">Github</a>
                    </div>
                  </div>
                </div>
              </div>
            </div>

            <!-- Research Item 2 -->
            <div class="card research-card">
              <div class="row g-0">
                <div class="col-md-4">
                  <div class="image-container">
                    <img src="images/research/images/complex_3goal.jpg" alt="Temporal Logic" class="research-image">
                  </div>
                </div>
                <div class="col-md-8">
                  <div class="card-body">
                    <h5 class="card-title">
                      <span class="papertitle">Temporal Logic Guided Robot Navigation</span>
                    </h5>
                    <p class="card-text">
                      <i>IFAC, 2024</i>
                    </p>
                    <p class="card-text">
                      <b>Aditya Parameshwaran</b>, Yue Wang
                    </p>
                    <div class="mb-2">
                      <span class="tech-tag">MATLAB</span>
                      <span class="tech-tag">Optimization</span>
                      <span class="tech-tag">Controls</span>
                      <span class="tech-tag">Mixed Integer Programming</span>
                    </div>
                    <p class="card-text">
                      2D controller synthesis combining Linear and Signal Temporal Logic specifications to gurantee
                      safe
                      and robust navigation for ground robots. This method is an update on the SAE Paper from 2023 and
                      is faster while maintaining similar levels of safety as before. It is published as part of the
                      IFAC papers in the MECC 2024 conference.
                    </p>
                    <div class="mt-3">
                      <a href="https://www.sciencedirect.com/science/article/pii/S2405896325001387" target="_blank"
                        class="btn btn-sm btn-outline-primary me-2">Paper</a>
                      <a href="https://github.com/aparame/Faster_TLG-RN" target="_blank"
                        class="btn btn-sm btn-outline-primary">Github</a>
                    </div>
                  </div>
                </div>
              </div>
            </div>

            <!-- Research Item 3-->
            <div class="card research-card">
              <div class="row g-0">
                <div class="col-md-4">
                  <div class="dual-media-container">
                    <div class="media-item">
                      <img src="images/research/images/safety-verification.png" alt="Safety Verification"
                        class="research-image">
                    </div>
                    <div class="media-item">
                      <img src="images/research/gifs/mw_2.gif" alt="Safety Verification Animation" class="animated-gif">
                    </div>
                  </div>
                </div>
                <div class="col-md-8">
                  <div class="card-body">
                    <h5 class="card-title">
                      <a href="https://scholar.google.com/citations?view_op=view_citation&hl=en&user=Oz75U7wAAAAJ&citation_for_view=Oz75U7wAAAAJ:u5HHmVD_uO8C"
                        target="_blank" class="text-decoration-none">
                        <span class="papertitle">Safety Verification of Autonomous Vehicles based on Signal Temporal
                          Logic (STL) constraints (SAE 2023)</span>
                      </a>
                    </h5>
                    <p class="card-text">
                      <b>Aditya Parameshwaran</b>, Yue Wang
                    </p>
                    <p class="card-text">
                      2D navigation model for an autonomous vehicle based on task specifications given in signal
                      temporal logic (STL) guaranteeing safety. This work is presented in the SAE WCX 2023 conference
                      at Detroit.
                    </p>
                    <div class="mt-3">
                      <a href="https://drive.google.com/file/d/1-9hnOEj0WTeBWehGWztxvabiHVWpZPeI/view" target="_blank"
                        class="btn btn-sm btn-outline-primary me-2">Paper</a>
                      <a href="https://docs.google.com/presentation/d/1iYR8xlaLWW_LBy45rsd_VEJTerPy_VyL/edit?usp=sharing&ouid=115261715409316286458&rtpof=true&sd=true"
                        target="_blank" class="btn btn-sm btn-outline-primary me-2">Slides</a>
                      <a href="https://github.com/aparame/Temporal_Logic_Guided_Robot_Navigation" target="_blank"
                        class="btn btn-sm btn-outline-primary">Github</a>
                    </div>
                  </div>
                </div>
              </div>
            </div>


            <!-- Research Item 3 -->
            <div class="card research-card">
              <div class="row g-0">
                <div class="col-md-4">
                  <div class="image-container">
                    <img src="images/research/images/approach.png" alt="Terrain Analysis" class="research-image">
                  </div>
                </div>
                <div class="col-md-8">
                  <div class="card-body">
                    <h5 class="card-title">
                      <span class="papertitle">Real-Time Terrain Analysis and Control for off-road Mobile
                        Robots</span>
                    </h5>
                    <p class="card-text">
                      Edwina Lewis, <b>Aditya Parameshwaran</b>
                    </p>
                    <p class="card-text">
                      Bayesian Calibration Routine based off-road terrain roughness estimator combined with Simplex
                      controller for mobile robots. This work is applied on
                      NVIDIA's Isaac Sim environment along with Jackal robot to collect IMU data and predict the
                      roughness of the terrain. The roughness estimates allow a Simplex controller to switch between
                      performance and safety modes of operation. This work is part of the
                      SAE WCX 2025 Conference at Detroit.
                    </p>
                    <div class="mt-3">
                      <a href="#" target="_blank" class="btn btn-sm btn-outline-primary me-2">Paper</a>
                      <a href="#" target="_blank" class="btn btn-sm btn-outline-primary">Github</a>
                    </div>
                  </div>
                </div>
              </div>
            </div>
        </section>


        <!-- Projects Section -->
        <section class="content-container" id="projects">
          <div class="section-header">
            <h3 class="section-title">Projects</h3>
          </div>

          <p class="mb-4">
            I have been involved in various robotics projects since completing my MS at Purdue, some in collaboration
            with companies like <a href="#project-railbot">Wabtec Corporation</a>,
            and others as side projects for the <a href="#project-octomap">US Army VIPR Centre</a>. These projects
            have spanned areas such as <a href="#project-controls">Controls</a>,
            <a href="#project-dl">Deep Learning</a>, <a href="#project-AV">Autonomous Navigation</a>, and <a
              href="#project-cv">Computer Vision</a>.
          </p>

          <!-- Project Item 1 -->
          <div class="grid-container">
            <!-- Jackal Project -->
            <article id="project-sharedcontrol" class="card">
              <div class="card-media-wrapper">
                <video class="card-img cover" autoplay loop muted playsinline>
                  <source src="images/Jackal_switching_control.mp4" type="video/mp4">
                  Your browser does not support the video tag.
                </video>
                <div class="card-icon-overlay"><i class="bi bi-play-circle fs-3"></i></div>
              </div>
              <div class="card-content">
                <div class="card-meta">
                  <span class="card-type">Robotics & Control</span>
                </div>
                <h4 class="card-title">
                  <span>Runtime Obstacle Avoidance & Shared Control</span>
                </h4>
                <div class="tech-stack">
                  <span class="tech-tag">ROS</span>
                  <span class="tech-tag">Jackal</span>
                  <span class="tech-tag">Shared Control</span>
                </div>
                <p class="card-desc">
                  Jackal robot controlled by a human, which does runtime obstacle avoidance, and takes over human
                  control
                  if an obstacle is too close to it and autonomously moves away.
                </p>
              </div>
            </article>

            <!-- Pick and Place -->
            <article id="project-PickandPlace" class="card">
              <div class="card-media-wrapper">
                <img src="images/research/gifs/moveit.gif" alt="Moveit GIF" class="card-img cover animated-gif">
              </div>
              <div class="card-content">
                <div class="card-meta">
                  <span class="card-type">Manipulation</span>
                </div>
                <h4 class="card-title">
                  <span>Pick and Place Task using MoveIt framework</span>
                </h4>
                <div class="tech-stack">
                  <span class="tech-tag">ROS2</span>
                  <span class="tech-tag">C++</span>
                  <span class="tech-tag">IsaacSim</span>
                  <span class="tech-tag">MoveIt</span>
                </div>
                <p class="card-desc">
                  A pick and place task using a UR5 manipulator developed based on the MoveIt framework in ROS2
                  and C++. The task involves identifying objects and planning safe trajectories in Isaac Sim.
                </p>
              </div>
            </article>

            <!-- RailBot -->
            <article id="project-railbot" class="card">
              <div class="card-media-wrapper">
                <img src="images/research/images/railbot.jpg" alt="Railway Robot" class="card-img cover project-image">
              </div>
              <div class="card-content">
                <div class="card-meta">
                  <span class="card-type">Autonomous Systems</span>
                </div>
                <h4 class="card-title">
                  <span>Autonomous Train Robot for Track Health Monitoring</span>
                </h4>
                <div class="tech-stack">
                  <span class="tech-tag">ROS</span>
                  <span class="tech-tag">Python</span>
                  <span class="tech-tag">PyTorch</span>
                  <span class="tech-tag">Jetson AGX</span>
                </div>
                <p class="card-desc">
                  Developed an autonomous railway bot for track health monitoring using LiDAR, stereo cameras, and IMU.
                  Deployed CNN models for real-time traffic sign recognition.
                </p>
              </div>
            </article>

            <!-- AV RC Car -->
            <article id="project-AV" class="card">
              <div class="card-media-wrapper">
                <img src="images/research/images/rc_car.jpg" alt="RC Car" class="card-img cover project-image">
              </div>
              <div class="card-content">
                <div class="card-meta">
                  <span class="card-type">Deep Learning</span>
                </div>
                <h4 class="card-title">
                  <span>Autonomous RC Car with Traffic Sign Identification</span>
                </h4>
                <div class="tech-stack">
                  <span class="tech-tag">MATLAB</span>
                  <span class="tech-tag">PyTorch</span>
                  <span class="tech-tag">OpenCV</span>
                  <span class="tech-tag">Computer Vision</span>
                </div>
                <p class="card-desc">
                  Developed an autonomous lane-keeping and sign-detecting RC car using ResNet-based CNNs and OpenCV for
                  track navigation.
                </p>
                <div class="card-links">
                  <a href="https://drive.google.com/file/d/1PvhqNhtHjqh15I8arVBqJ329xoe5nkOL/view" target="_blank"
                    class="card-link">Paper</a>
                  <a href="https://github.com/aparame/AI_RC_Car" target="_blank" class="card-link">Github</a>
                </div>
              </div>
            </article>

            <!-- Octomap -->
            <article id="project-octomap" class="card">
              <div class="card-media-wrapper">
                <img src="images/research/gifs/octomap.gif" alt="Octomap GIF" class="card-img cover animated-gif">
              </div>
              <div class="card-content">
                <div class="card-meta">
                  <span class="card-type">3D Mapping</span>
                </div>
                <h4 class="card-title">
                  <span>Semantic Segmentation and 3D Map Generation</span>
                </h4>
                <div class="tech-stack">
                  <span class="tech-tag">ROS2</span>
                  <span class="tech-tag">C++</span>
                  <span class="tech-tag">Sensor Fusion</span>
                  <span class="tech-tag">Octomap</span>
                </div>
                <p class="card-desc">
                  Generated semantically segmented 3D voxel maps by fusing RGB data with LiDAR point clouds using the
                  Octomap library in outdoor environments.
                </p>
              </div>
            </article>
          </div>

        </section>


        <!-- Footer / Map -->
        <div class="footer-map">
          <a href="https://clustrmaps.com/site/1bzsm" title="Visit tracker">
            <img src="//www.clustrmaps.com/map_v2.png?d=CohQDJ03hYE1HZTkcj3jQZrHggxMQALIKVQO070CtSM&cl=ffffff"
              alt="Visitor Map" />
          </a>
        </div>
      </div>
    </main>
  </div>
  </div>

  <!-- Lightbox Modal -->
  <div id="imageModal" class="modal">
    <span class="close">&times;</span>
    <div class="modal-content-container">
      <img class="modal-content" id="modalImage">
    </div>
    <div id="caption"></div>
  </div>

  <script>
    // Lightbox Logic
    const modal = document.getElementById("imageModal");
    const modalImg = document.getElementById("modalImage");
    const captionText = document.getElementById("caption");
    const closeBtn = document.getElementsByClassName("close")[0];

    // Function to initialize clickable images
    function initLightbox() {
      // Get all images that should be clickable
      const images = document.querySelectorAll('.research-image, .project-image, .animated-gif, .profile-image');

      // Add click event to each image
      images.forEach(img => {
        img.addEventListener('click', function () {
          modal.style.display = "block";
          modalImg.src = this.src;
          captionText.innerHTML = this.alt;

          // Disable scrolling on the body when modal is open
          document.body.style.overflow = "hidden";
        });
      });

      // Close the modal when clicking the Ã— button
      closeBtn.addEventListener('click', closeModal);

      // Close the modal when clicking outside the image
      modal.addEventListener('click', function (event) {
        if (event.target === modal) {
          closeModal();
        }
      });

      // Close modal with Escape key
      document.addEventListener('keydown', function (event) {
        if (event.key === "Escape") {
          closeModal();
        }
      });
    }


    function closeModal() {
      modal.style.display = "none";
      document.body.style.overflow = "auto";
    }

    // Initialize the lightbox after the page loads
    document.addEventListener('DOMContentLoaded', initLightbox);
  </script>
</body>

</html>